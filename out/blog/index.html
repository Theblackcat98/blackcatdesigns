<!DOCTYPE html><!--mqoiKBG41VDaIdpl__yaH--><html lang="en" class="dark scroll-smooth"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="stylesheet" href="/_next/static/css/3499fdfcb29162bf.css" data-precedence="next"/><link rel="preload" as="script" fetchPriority="low" href="/_next/static/chunks/webpack-bc04d6136a8cc3fe.js"/><script src="/_next/static/chunks/4bd1b696-c023c6e3521b1417.js" async=""></script><script src="/_next/static/chunks/255-0fb808ac7cfa018d.js" async=""></script><script src="/_next/static/chunks/main-app-bd5f0190a3018ae2.js" async=""></script><script src="/_next/static/chunks/215-388a4da7c5323a15.js" async=""></script><script src="/_next/static/chunks/app/layout-325168dde6378f38.js" async=""></script><script src="/_next/static/chunks/619-ba102abea3e3d0e4.js" async=""></script><script src="/_next/static/chunks/356-1fcf197c11312f1f.js" async=""></script><script src="/_next/static/chunks/app/page-4b91671b22564e8d.js" async=""></script><script src="/_next/static/chunks/app/blog/page-546ed3538b42ce2a.js" async=""></script><title>Portfolio &amp; Blog</title><meta name="description" content="Personal portfolio and blog featuring my work and thoughts"/><link href="https://api.fontshare.com/v2/css?f[]=clash-display@400,500,600,700&amp;f[]=satoshi@300,400,500,700,900&amp;display=swap" rel="stylesheet"/><link href="https://fonts.googleapis.com/css2?family=DM+Serif+Text:ital@0;1&amp;display=swap" rel="stylesheet"/><script src="/_next/static/chunks/polyfills-42372ed130431b0a.js" noModule=""></script></head><body class="flex flex-col min-h-screen overflow-x-hidden" style="background-color:var(--bg-primary);color:var(--text-primary)"><div hidden=""><!--$--><!--/$--></div><div class="fixed inset-0 pointer-events-none z-50 opacity-[0.03] mix-blend-overlay" style="background-image:url(&quot;data:image/svg+xml,%3Csvg viewBox=&#x27;0 0 200 200&#x27; xmlns=&#x27;http://www.w3.org/2000/svg&#x27;%3E%3Cfilter id=&#x27;noiseFilter&#x27;%3E%3CfeTurbulence type=&#x27;fractalNoise&#x27; baseFrequency=&#x27;0.65&#x27; numOctaves=&#x27;3&#x27; stitchTiles=&#x27;stitch&#x27;/%3E%3C/filter%3E%3Crect width=&#x27;100%25&#x27; height=&#x27;100%25&#x27; filter=&#x27;url(%23noiseFilter)&#x27;/%3E%3C/svg%3E&quot;)"></div><header class="fixed top-6 left-1/2 transform -translate-x-1/2 z-50 rounded-full" style="background-color:rgba(26, 26, 26, 0.9);backdrop-filter:blur(10px);-webkit-backdrop-filter:blur(10px);border:1px solid #333;box-shadow:0 8px 32px rgba(0, 0, 0, 0.3)"><nav class="flex items-center justify-between gap-10 px-8 py-3" style="max-width:600px"><a href="/" class="text-xl font-bold transition-colors whitespace-nowrap" style="color:#ffffff">BlackCatDesigns</a><div class="hidden md:flex items-center gap-8"><div class="flex space-x-7"><div style="position:relative"><a href="/" class="relative font-medium text-sm transition-all duration-300 text-gray-400 hover:text-white" style="text-decoration:none;position:relative">Home<span class="absolute bottom-[-5px] left-1/2 transform -translate-x-1/2 h-[2px] bg-white transition-all duration-300 w-0 hover:w-full"></span></a></div><div style="position:relative"><a href="/projects" class="relative font-medium text-sm transition-all duration-300 text-gray-400 hover:text-white" style="text-decoration:none;position:relative">Projects<span class="absolute bottom-[-5px] left-1/2 transform -translate-x-1/2 h-[2px] bg-white transition-all duration-300 w-0 hover:w-full"></span></a></div><div style="position:relative"><a href="/blog" class="relative font-medium text-sm transition-all duration-300 text-gray-400 hover:text-white" style="text-decoration:none;position:relative">Blog<span class="absolute bottom-[-5px] left-1/2 transform -translate-x-1/2 h-[2px] bg-white transition-all duration-300 w-0 hover:w-full"></span></a></div><div style="position:relative"><a href="/about" class="relative font-medium text-sm transition-all duration-300 text-gray-400 hover:text-white" style="text-decoration:none;position:relative">About<span class="absolute bottom-[-5px] left-1/2 transform -translate-x-1/2 h-[2px] bg-white transition-all duration-300 w-0 hover:w-full"></span></a></div><div style="position:relative"><a href="/contact" class="relative font-medium text-sm transition-all duration-300 text-gray-400 hover:text-white" style="text-decoration:none;position:relative">Contact<span class="absolute bottom-[-5px] left-1/2 transform -translate-x-1/2 h-[2px] bg-white transition-all duration-300 w-0 hover:w-full"></span></a></div></div><div class="flex gap-4 items-center"><a href="#" class="px-5 py-2 rounded-full text-sm font-medium transition-all duration-300 border border-gray-500 text-gray-300 hover:text-white hover:border-gray-400" style="text-decoration:none">Login</a><a href="#" class="px-5 py-2 rounded-full text-sm font-medium transition-all duration-300 bg-white text-black hover:bg-gray-100 hover:-translate-y-0.5 whitespace-nowrap" style="text-decoration:none">Sign Up</a></div></div><button class="md:hidden text-white text-xl cursor-pointer">â˜°</button></nav><div id="navLinks" class="hidden absolute top-full left-0 right-0 mt-2 rounded-lg bg-gray-900 bg-opacity-95 p-5 flex-col gap-4 md:!hidden"><div class="flex flex-col gap-4"><div style="position:relative"><a href="/" class="relative font-medium text-sm transition-all duration-300 text-gray-400 hover:text-white" style="text-decoration:none;position:relative">Home<span class="absolute bottom-[-5px] left-1/2 transform -translate-x-1/2 h-[2px] bg-white transition-all duration-300 w-0 hover:w-full"></span></a></div><div style="position:relative"><a href="/projects" class="relative font-medium text-sm transition-all duration-300 text-gray-400 hover:text-white" style="text-decoration:none;position:relative">Projects<span class="absolute bottom-[-5px] left-1/2 transform -translate-x-1/2 h-[2px] bg-white transition-all duration-300 w-0 hover:w-full"></span></a></div><div style="position:relative"><a href="/blog" class="relative font-medium text-sm transition-all duration-300 text-gray-400 hover:text-white" style="text-decoration:none;position:relative">Blog<span class="absolute bottom-[-5px] left-1/2 transform -translate-x-1/2 h-[2px] bg-white transition-all duration-300 w-0 hover:w-full"></span></a></div><div style="position:relative"><a href="/about" class="relative font-medium text-sm transition-all duration-300 text-gray-400 hover:text-white" style="text-decoration:none;position:relative">About<span class="absolute bottom-[-5px] left-1/2 transform -translate-x-1/2 h-[2px] bg-white transition-all duration-300 w-0 hover:w-full"></span></a></div><div style="position:relative"><a href="/contact" class="relative font-medium text-sm transition-all duration-300 text-gray-400 hover:text-white" style="text-decoration:none;position:relative">Contact<span class="absolute bottom-[-5px] left-1/2 transform -translate-x-1/2 h-[2px] bg-white transition-all duration-300 w-0 hover:w-full"></span></a></div></div><div class="flex flex-col gap-3 pt-4 border-t border-gray-600"><a href="#" class="px-5 py-2 rounded-full text-sm font-medium transition-all duration-300 border border-gray-500 text-gray-300 hover:text-white hover:border-gray-400 text-center" style="text-decoration:none">Login</a><a href="#" class="px-5 py-2 rounded-full text-sm font-medium transition-all duration-300 bg-white text-black hover:bg-gray-100 hover:-translate-y-0.5 text-center" style="text-decoration:none">Sign Up</a></div></div></header><main class="max-w-4xl mx-auto px-6 pt-24 pb-12 flex-grow w-full"><div class="space-y-8"><div class="flex items-start justify-between gap-4"><div><h1 class="text-4xl font-bold mb-2" style="color:var(--text-primary)">Blog</h1><p style="color:var(--text-secondary)">Thoughts on web development, technology, and more.</p></div><button class="flex items-center gap-2 px-3 py-1.5 text-sm border rounded-lg transition-colors" style="background-color:var(--bg-tertiary);border-color:var(--bg-border);color:var(--text-muted)"><svg class="w-4 h-4" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M21 21l-6-6m2-5a7 7 0 11-14 0 7 7 0 0114 0z"></path></svg><span class="hidden sm:inline">Search</span><kbd class="hidden sm:inline text-xs px-1.5 py-0.5 rounded" style="background-color:var(--bg-border)">âŒ˜K</kbd></button></div><div class="relative"><input type="text" placeholder="Search posts..." class="w-full px-4 py-3 transition rounded-lg" style="background-color:var(--bg-secondary);border-color:var(--bg-border);color:var(--text-primary);border:1px solid var(--bg-border)" value=""/><svg class="absolute right-3 top-3.5 w-5 h-5 text-gray-500" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M21 21l-6-6m2-5a7 7 0 11-14 0 7 7 0 0114 0z"></path></svg></div><div class="space-y-3"><p class="text-sm font-semibold" style="color:var(--text-secondary)">Filter by category:</p><div class="flex flex-wrap gap-2"><button class="px-4 py-2 text-sm font-medium transition-colors" style="background-color:var(--accent);color:var(--bg-primary);border-radius:var(--radius-full);border:none">All Posts</button><button class="px-4 py-2 text-sm font-medium transition-colors" style="background-color:var(--bg-tertiary);color:var(--text-secondary);border-radius:var(--radius-full);border:1px solid var(--bg-border)">2025</button><button class="px-4 py-2 text-sm font-medium transition-colors" style="background-color:var(--bg-tertiary);color:var(--text-secondary);border-radius:var(--radius-full);border:1px solid var(--bg-border)">AI Evaluation</button><button class="px-4 py-2 text-sm font-medium transition-colors" style="background-color:var(--bg-tertiary);color:var(--text-secondary);border-radius:var(--radius-full);border:1px solid var(--bg-border)">AI prompts</button><button class="px-4 py-2 text-sm font-medium transition-colors" style="background-color:var(--bg-tertiary);color:var(--text-secondary);border-radius:var(--radius-full);border:1px solid var(--bg-border)">Benchmarking</button><button class="px-4 py-2 text-sm font-medium transition-colors" style="background-color:var(--bg-tertiary);color:var(--text-secondary);border-radius:var(--radius-full);border:1px solid var(--bg-border)">Future Challenges</button><button class="px-4 py-2 text-sm font-medium transition-colors" style="background-color:var(--bg-tertiary);color:var(--text-secondary);border-radius:var(--radius-full);border:1px solid var(--bg-border)">LLM evolution</button><button class="px-4 py-2 text-sm font-medium transition-colors" style="background-color:var(--bg-tertiary);color:var(--text-secondary);border-radius:var(--radius-full);border:1px solid var(--bg-border)">LLMs</button><button class="px-4 py-2 text-sm font-medium transition-colors" style="background-color:var(--bg-tertiary);color:var(--text-secondary);border-radius:var(--radius-full);border:1px solid var(--bg-border)">OpenWebUI</button><button class="px-4 py-2 text-sm font-medium transition-colors" style="background-color:var(--bg-tertiary);color:var(--text-secondary);border-radius:var(--radius-full);border:1px solid var(--bg-border)">Tools</button><button class="px-4 py-2 text-sm font-medium transition-colors" style="background-color:var(--bg-tertiary);color:var(--text-secondary);border-radius:var(--radius-full);border:1px solid var(--bg-border)">ai</button><button class="px-4 py-2 text-sm font-medium transition-colors" style="background-color:var(--bg-tertiary);color:var(--text-secondary);border-radius:var(--radius-full);border:1px solid var(--bg-border)">deep research agents</button><button class="px-4 py-2 text-sm font-medium transition-colors" style="background-color:var(--bg-tertiary);color:var(--text-secondary);border-radius:var(--radius-full);border:1px solid var(--bg-border)">design</button><button class="px-4 py-2 text-sm font-medium transition-colors" style="background-color:var(--bg-tertiary);color:var(--text-secondary);border-radius:var(--radius-full);border:1px solid var(--bg-border)">development</button><button class="px-4 py-2 text-sm font-medium transition-colors" style="background-color:var(--bg-tertiary);color:var(--text-secondary);border-radius:var(--radius-full);border:1px solid var(--bg-border)">first-post</button><button class="px-4 py-2 text-sm font-medium transition-colors" style="background-color:var(--bg-tertiary);color:var(--text-secondary);border-radius:var(--radius-full);border:1px solid var(--bg-border)">hallucination mitigation</button><button class="px-4 py-2 text-sm font-medium transition-colors" style="background-color:var(--bg-tertiary);color:var(--text-secondary);border-radius:var(--radius-full);border:1px solid var(--bg-border)">llama-cpp</button><button class="px-4 py-2 text-sm font-medium transition-colors" style="background-color:var(--bg-tertiary);color:var(--text-secondary);border-radius:var(--radius-full);border:1px solid var(--bg-border)">local-llm</button><button class="px-4 py-2 text-sm font-medium transition-colors" style="background-color:var(--bg-tertiary);color:var(--text-secondary);border-radius:var(--radius-full);border:1px solid var(--bg-border)">markdown</button><button class="px-4 py-2 text-sm font-medium transition-colors" style="background-color:var(--bg-tertiary);color:var(--text-secondary);border-radius:var(--radius-full);border:1px solid var(--bg-border)">ollama</button><button class="px-4 py-2 text-sm font-medium transition-colors" style="background-color:var(--bg-tertiary);color:var(--text-secondary);border-radius:var(--radius-full);border:1px solid var(--bg-border)">prompt engineering</button><button class="px-4 py-2 text-sm font-medium transition-colors" style="background-color:var(--bg-tertiary);color:var(--text-secondary);border-radius:var(--radius-full);border:1px solid var(--bg-border)">self-hosted</button><button class="px-4 py-2 text-sm font-medium transition-colors" style="background-color:var(--bg-tertiary);color:var(--text-secondary);border-radius:var(--radius-full);border:1px solid var(--bg-border)">ui-ux</button><button class="px-4 py-2 text-sm font-medium transition-colors" style="background-color:var(--bg-tertiary);color:var(--text-secondary);border-radius:var(--radius-full);border:1px solid var(--bg-border)">welcome</button><button class="px-4 py-2 text-sm font-medium transition-colors" style="background-color:var(--bg-tertiary);color:var(--text-secondary);border-radius:var(--radius-full);border:1px solid var(--bg-border)">writing</button></div></div><div class="space-y-6"><p class="text-sm" style="color:var(--text-muted)">Showing <!-- -->6<!-- --> of <!-- -->6<!-- --> posts</p><article class="border rounded-lg p-6 transition" style="border-color:var(--bg-border);background-color:var(--bg-secondary)"><a class="group" href="/blog/benchmarks-and-llms/"><h2 class="text-2xl font-semibold mb-2 transition" style="color:var(--text-primary)">Evaluating New LLMs: Why It&#x27;s Getting Harder and What to Do</h2></a><div class="flex items-center gap-3 mb-3 flex-wrap"><time class="text-sm" style="color:var(--text-muted)">November 27, 2025</time><span class="text-sm" style="color:var(--text-muted)">Â· <!-- -->6<!-- --> min read</span><span class="text-sm" style="color:var(--text-muted)">Â· by <!-- -->theblackcat</span></div><p class="mb-4" style="color:var(--text-secondary)">Explanatory strategies for benchmarking amid rapid AI releases. Covering custom tests, tools, and future challenges.</p><div class="flex gap-2 flex-wrap"><a class="text-xs px-3 py-1 border transition-colors" style="background-color:var(--bg-tertiary);color:var(--accent-hover);border-color:var(--bg-border);border-radius:var(--radius-md)" href="/blog/tag/AI%20Evaluation/">AI Evaluation</a><a class="text-xs px-3 py-1 border transition-colors" style="background-color:var(--bg-tertiary);color:var(--accent-hover);border-color:var(--bg-border);border-radius:var(--radius-md)" href="/blog/tag/LLMs/">LLMs</a><a class="text-xs px-3 py-1 border transition-colors" style="background-color:var(--bg-tertiary);color:var(--accent-hover);border-color:var(--bg-border);border-radius:var(--radius-md)" href="/blog/tag/Benchmarking/">Benchmarking</a><a class="text-xs px-3 py-1 border transition-colors" style="background-color:var(--bg-tertiary);color:var(--accent-hover);border-color:var(--bg-border);border-radius:var(--radius-md)" href="/blog/tag/Tools/">Tools</a><a class="text-xs px-3 py-1 border transition-colors" style="background-color:var(--bg-tertiary);color:var(--accent-hover);border-color:var(--bg-border);border-radius:var(--radius-md)" href="/blog/tag/Future%20Challenges/">Future Challenges</a></div><a class="mt-4 inline-block font-medium transition-colors" style="color:var(--accent)" href="/blog/benchmarks-and-llms/">Read more â†’</a></article><article class="border rounded-lg p-6 transition" style="border-color:var(--bg-border);background-color:var(--bg-secondary)"><a class="group" href="/blog/llm-starter-guide/"><h2 class="text-2xl font-semibold mb-2 transition" style="color:var(--text-primary)">Getting Started with Local LLMs: 2025 Beginnerâ€™s Guide</h2></a><div class="flex items-center gap-3 mb-3 flex-wrap"><time class="text-sm" style="color:var(--text-muted)">November 27, 2025</time><span class="text-sm" style="color:var(--text-muted)">Â· <!-- -->4<!-- --> min read</span><span class="text-sm" style="color:var(--text-muted)">Â· by <!-- -->theblackcat</span></div><p class="mb-4" style="color:var(--text-secondary)">A clear, no-nonsense guide to running powerful large language models on your own hardware in 2025 â€“ perfect for beginners and power users alike.</p><div class="flex gap-2 flex-wrap"><a class="text-xs px-3 py-1 border transition-colors" style="background-color:var(--bg-tertiary);color:var(--accent-hover);border-color:var(--bg-border);border-radius:var(--radius-md)" href="/blog/tag/local-llm/">local-llm</a><a class="text-xs px-3 py-1 border transition-colors" style="background-color:var(--bg-tertiary);color:var(--accent-hover);border-color:var(--bg-border);border-radius:var(--radius-md)" href="/blog/tag/ai/">ai</a><a class="text-xs px-3 py-1 border transition-colors" style="background-color:var(--bg-tertiary);color:var(--accent-hover);border-color:var(--bg-border);border-radius:var(--radius-md)" href="/blog/tag/ollama/">ollama</a><a class="text-xs px-3 py-1 border transition-colors" style="background-color:var(--bg-tertiary);color:var(--accent-hover);border-color:var(--bg-border);border-radius:var(--radius-md)" href="/blog/tag/llama-cpp/">llama-cpp</a><a class="text-xs px-3 py-1 border transition-colors" style="background-color:var(--bg-tertiary);color:var(--accent-hover);border-color:var(--bg-border);border-radius:var(--radius-md)" href="/blog/tag/self-hosted/">self-hosted</a><a class="text-xs px-3 py-1 border transition-colors" style="background-color:var(--bg-tertiary);color:var(--accent-hover);border-color:var(--bg-border);border-radius:var(--radius-md)" href="/blog/tag/2025/">2025</a></div><a class="mt-4 inline-block font-medium transition-colors" style="color:var(--accent)" href="/blog/llm-starter-guide/">Read more â†’</a></article><article class="border rounded-lg p-6 transition" style="border-color:var(--bg-border);background-color:var(--bg-secondary)"><a class="group" href="/blog/system-prompts-of-the-past/"><h2 class="text-2xl font-semibold mb-2 transition" style="color:var(--text-primary)">The Evolution of System Prompts for Deep Research Agents</h2></a><div class="flex items-center gap-3 mb-3 flex-wrap"><time class="text-sm" style="color:var(--text-muted)">November 27, 2025</time><span class="text-sm" style="color:var(--text-muted)">Â· <!-- -->6<!-- --> min read</span><span class="text-sm" style="color:var(--text-muted)">Â· by <!-- -->theblackcat</span></div><p class="mb-4" style="color:var(--text-secondary)">From simple instructions in early GPTs to sophisticated chain-of-thought structures in 2025 tools like OpenWebUI, this post traces how prompts have transformed AI research capabilities. Explore historical shifts, key techniques, challenges, and forward-looking experiments.</p><div class="flex gap-2 flex-wrap"><a class="text-xs px-3 py-1 border transition-colors" style="background-color:var(--bg-tertiary);color:var(--accent-hover);border-color:var(--bg-border);border-radius:var(--radius-md)" href="/blog/tag/AI%20prompts/">AI prompts</a><a class="text-xs px-3 py-1 border transition-colors" style="background-color:var(--bg-tertiary);color:var(--accent-hover);border-color:var(--bg-border);border-radius:var(--radius-md)" href="/blog/tag/prompt%20engineering/">prompt engineering</a><a class="text-xs px-3 py-1 border transition-colors" style="background-color:var(--bg-tertiary);color:var(--accent-hover);border-color:var(--bg-border);border-radius:var(--radius-md)" href="/blog/tag/deep%20research%20agents/">deep research agents</a><a class="text-xs px-3 py-1 border transition-colors" style="background-color:var(--bg-tertiary);color:var(--accent-hover);border-color:var(--bg-border);border-radius:var(--radius-md)" href="/blog/tag/LLM%20evolution/">LLM evolution</a><a class="text-xs px-3 py-1 border transition-colors" style="background-color:var(--bg-tertiary);color:var(--accent-hover);border-color:var(--bg-border);border-radius:var(--radius-md)" href="/blog/tag/OpenWebUI/">OpenWebUI</a><a class="text-xs px-3 py-1 border transition-colors" style="background-color:var(--bg-tertiary);color:var(--accent-hover);border-color:var(--bg-border);border-radius:var(--radius-md)" href="/blog/tag/hallucination%20mitigation/">hallucination mitigation</a></div><a class="mt-4 inline-block font-medium transition-colors" style="color:var(--accent)" href="/blog/system-prompts-of-the-past/">Read more â†’</a></article><article class="border rounded-lg p-6 transition" style="border-color:var(--bg-border);background-color:var(--bg-secondary)"><a class="group" href="/blog/welcome/"><h2 class="text-2xl font-semibold mb-2 transition" style="color:var(--text-primary)">Welcome to My Blog</h2></a><div class="flex items-center gap-3 mb-3 flex-wrap"><time class="text-sm" style="color:var(--text-muted)">November 27, 2025</time><span class="text-sm" style="color:var(--text-muted)">Â· <!-- -->1<!-- --> min read</span><span class="text-sm" style="color:var(--text-muted)">Â· by <!-- -->You</span></div><p class="mb-4" style="color:var(--text-secondary)">An introduction to my personal blog and portfolio</p><div class="flex gap-2 flex-wrap"><a class="text-xs px-3 py-1 border transition-colors" style="background-color:var(--bg-tertiary);color:var(--accent-hover);border-color:var(--bg-border);border-radius:var(--radius-md)" href="/blog/tag/welcome/">welcome</a><a class="text-xs px-3 py-1 border transition-colors" style="background-color:var(--bg-tertiary);color:var(--accent-hover);border-color:var(--bg-border);border-radius:var(--radius-md)" href="/blog/tag/first-post/">first-post</a></div><a class="mt-4 inline-block font-medium transition-colors" style="color:var(--accent)" href="/blog/welcome/">Read more â†’</a></article><article class="border rounded-lg p-6 transition" style="border-color:var(--bg-border);background-color:var(--bg-secondary)"><a class="group" href="/blog/design-principles/"><h2 class="text-2xl font-semibold mb-2 transition" style="color:var(--text-primary)">Essential Design Principles</h2></a><div class="flex items-center gap-3 mb-3 flex-wrap"><time class="text-sm" style="color:var(--text-muted)">November 26, 2025</time><span class="text-sm" style="color:var(--text-muted)">Â· <!-- -->2<!-- --> min read</span><span class="text-sm" style="color:var(--text-muted)">Â· by <!-- -->You</span></div><p class="mb-4" style="color:var(--text-secondary)">Explore the fundamental principles that guide beautiful and functional design</p><div class="flex gap-2 flex-wrap"><a class="text-xs px-3 py-1 border transition-colors" style="background-color:var(--bg-tertiary);color:var(--accent-hover);border-color:var(--bg-border);border-radius:var(--radius-md)" href="/blog/tag/design/">design</a><a class="text-xs px-3 py-1 border transition-colors" style="background-color:var(--bg-tertiary);color:var(--accent-hover);border-color:var(--bg-border);border-radius:var(--radius-md)" href="/blog/tag/ui-ux/">ui-ux</a></div><a class="mt-4 inline-block font-medium transition-colors" style="color:var(--accent)" href="/blog/design-principles/">Read more â†’</a></article><article class="border rounded-lg p-6 transition" style="border-color:var(--bg-border);background-color:var(--bg-secondary)"><a class="group" href="/blog/markdown-cheatsheet/"><h2 class="text-2xl font-semibold mb-2 transition" style="color:var(--text-primary)">Markdown Cheat Sheet</h2></a><div class="flex items-center gap-3 mb-3 flex-wrap"><time class="text-sm" style="color:var(--text-muted)">November 25, 2025</time><span class="text-sm" style="color:var(--text-muted)">Â· <!-- -->2<!-- --> min read</span><span class="text-sm" style="color:var(--text-muted)">Â· by <!-- -->You</span></div><p class="mb-4" style="color:var(--text-secondary)">A cheat sheet to show all Markdown styles and features</p><div class="flex gap-2 flex-wrap"><a class="text-xs px-3 py-1 border transition-colors" style="background-color:var(--bg-tertiary);color:var(--accent-hover);border-color:var(--bg-border);border-radius:var(--radius-md)" href="/blog/tag/writing/">writing</a><a class="text-xs px-3 py-1 border transition-colors" style="background-color:var(--bg-tertiary);color:var(--accent-hover);border-color:var(--bg-border);border-radius:var(--radius-md)" href="/blog/tag/development/">development</a><a class="text-xs px-3 py-1 border transition-colors" style="background-color:var(--bg-tertiary);color:var(--accent-hover);border-color:var(--bg-border);border-radius:var(--radius-md)" href="/blog/tag/markdown/">markdown</a></div><a class="mt-4 inline-block font-medium transition-colors" style="color:var(--accent)" href="/blog/markdown-cheatsheet/">Read more â†’</a></article></div></div><!--$--><!--/$--></main><footer class="border-t mt-12" style="border-color:var(--bg-border);background-color:var(--bg-secondary)"><div class="max-w-4xl mx-auto px-6 py-12"><div class="grid grid-cols-1 md:grid-cols-3 gap-8 mb-8"><div><h3 class="text-lg font-bold mb-2" style="color:var(--accent)">BlackCatDesigns</h3><p class="text-sm" style="color:var(--text-muted)">Cultivating Aesthetic Transformations</p></div><div><h4 class="text-sm font-semibold mb-4" style="color:var(--text-secondary)">Navigation</h4><ul class="space-y-2 text-sm"><li><a href="/" class="transition-colors" style="color:var(--text-muted)">Home</a></li><li><a href="/projects" class="transition-colors" style="color:var(--text-muted)">Projects</a></li><li><a href="/blog" class="transition-colors" style="color:var(--text-muted)">Blog</a></li><li><a href="/about" class="transition-colors" style="color:var(--text-muted)">About</a></li><li><a href="/contact" class="transition-colors" style="color:var(--text-muted)">Contact</a></li></ul></div><div><h4 class="text-sm font-semibold mb-4" style="color:var(--text-secondary)">Connect</h4><ul class="space-y-2 text-sm"><li><a href="https://github.com/theblackcat98" target="_blank" rel="noopener noreferrer" class="transition-colors" style="color:var(--text-muted)"><span class="flex items-center gap-2"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-github w-4 h-4" aria-hidden="true"><path d="M15 22v-4a4.8 4.8 0 0 0-1-3.5c3 0 6-2 6-5.5.08-1.25-.27-2.48-1-3.5.28-1.15.28-2.35 0-3.5 0 0-1 0-3 1.5-2.64-.5-5.36-.5-8 0C6 2 5 2 5 2c-.3 1.15-.3 2.35 0 3.5A5.403 5.403 0 0 0 4 9c0 3.5 3 5.5 6 5.5-.39.49-.68 1.05-.85 1.65-.17.6-.22 1.23-.15 1.85v4"></path><path d="M9 18c-4.51 2-5-2-7-2"></path></svg>GitHub</span></a></li><li><a href="https://instagram.com/theblackcat98" target="_blank" rel="noopener noreferrer" class="transition-colors" style="color:var(--text-muted)"><span class="flex items-center gap-2"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-instagram w-4 h-4" aria-hidden="true"><rect width="20" height="20" x="2" y="2" rx="5" ry="5"></rect><path d="M16 11.37A4 4 0 1 1 12.63 8 4 4 0 0 1 16 11.37z"></path><line x1="17.5" x2="17.51" y1="6.5" y2="6.5"></line></svg>Instagram</span></a></li></ul></div></div><div class="border-t pt-6 text-center text-sm" style="border-color:var(--bg-border);color:var(--text-muted)"><p>Â© 2025 BlackCatDesigns. All rights reserved.</p></div></div></footer><script src="/_next/static/chunks/webpack-bc04d6136a8cc3fe.js" id="_R_" async=""></script><script>(self.__next_f=self.__next_f||[]).push([0])</script><script>self.__next_f.push([1,"1:\"$Sreact.fragment\"\n2:I[2260,[\"215\",\"static/chunks/215-388a4da7c5323a15.js\",\"177\",\"static/chunks/app/layout-325168dde6378f38.js\"],\"default\"]\n3:I[912,[\"215\",\"static/chunks/215-388a4da7c5323a15.js\",\"177\",\"static/chunks/app/layout-325168dde6378f38.js\"],\"default\"]\n4:I[9766,[],\"\"]\n5:I[8924,[],\"\"]\n6:I[2619,[\"619\",\"static/chunks/619-ba102abea3e3d0e4.js\",\"215\",\"static/chunks/215-388a4da7c5323a15.js\",\"356\",\"static/chunks/356-1fcf197c11312f1f.js\",\"974\",\"static/chunks/app/page-4b91671b22564e8d.js\"],\"\"]\n7:I[979,[\"215\",\"static/chunks/215-388a4da7c5323a15.js\",\"177\",\"static/chunks/app/layout-325168dde6378f38.js\"],\"default\"]\ne:I[7150,[],\"\"]\n:HL[\"/_next/static/css/3499fdfcb29162bf.css\",\"style\"]\n"])</script><script>self.__next_f.push([1,"0:{\"P\":null,\"b\":\"mqoiKBG41VDaIdpl--yaH\",\"p\":\"\",\"c\":[\"\",\"blog\",\"\"],\"i\":false,\"f\":[[[\"\",{\"children\":[\"blog\",{\"children\":[\"__PAGE__\",{}]}]},\"$undefined\",\"$undefined\",true],[\"\",[\"$\",\"$1\",\"c\",{\"children\":[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/3499fdfcb29162bf.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"$undefined\"}]],[\"$\",\"html\",null,{\"lang\":\"en\",\"className\":\"dark scroll-smooth\",\"suppressHydrationWarning\":true,\"children\":[[\"$\",\"head\",null,{\"children\":[[\"$\",\"link\",null,{\"href\":\"https://api.fontshare.com/v2/css?f[]=clash-display@400,500,600,700\u0026f[]=satoshi@300,400,500,700,900\u0026display=swap\",\"rel\":\"stylesheet\"}],[\"$\",\"link\",null,{\"href\":\"https://fonts.googleapis.com/css2?family=DM+Serif+Text:ital@0;1\u0026display=swap\",\"rel\":\"stylesheet\"}]]}],[\"$\",\"body\",null,{\"className\":\"flex flex-col min-h-screen overflow-x-hidden\",\"style\":{\"backgroundColor\":\"var(--bg-primary)\",\"color\":\"var(--text-primary)\"},\"children\":[[\"$\",\"$L2\",null,{}],[\"$\",\"div\",null,{\"className\":\"fixed inset-0 pointer-events-none z-50 opacity-[0.03] mix-blend-overlay\",\"style\":{\"backgroundImage\":\"url(\\\"data:image/svg+xml,%3Csvg viewBox='0 0 200 200' xmlns='http://www.w3.org/2000/svg'%3E%3Cfilter id='noiseFilter'%3E%3CfeTurbulence type='fractalNoise' baseFrequency='0.65' numOctaves='3' stitchTiles='stitch'/%3E%3C/filter%3E%3Crect width='100%25' height='100%25' filter='url(%23noiseFilter)'/%3E%3C/svg%3E\\\")\"}}],[\"$\",\"$L3\",null,{}],[\"$\",\"main\",null,{\"className\":\"max-w-4xl mx-auto px-6 pt-24 pb-12 flex-grow w-full\",\"children\":[\"$\",\"$L4\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L5\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[[\"$\",\"div\",null,{\"className\":\"flex flex-col items-center justify-center min-h-[400px] gap-6 text-center\",\"children\":[[\"$\",\"h1\",null,{\"className\":\"text-6xl font-bold\",\"style\":{\"color\":\"var(--text-primary)\"},\"children\":\"404\"}],[\"$\",\"h2\",null,{\"className\":\"text-2xl font-semibold\",\"style\":{\"color\":\"var(--text-secondary)\"},\"children\":\"Page Not Found\"}],[\"$\",\"p\",null,{\"style\":{\"color\":\"var(--text-muted)\"},\"children\":\"The page you're looking for doesn't exist.\"}],[\"$\",\"$L6\",null,{\"href\":\"/\",\"className\":\"mt-4 px-6 py-3 font-medium transition-colors\",\"style\":{\"backgroundColor\":\"var(--accent)\",\"color\":\"var(--bg-primary)\"},\"children\":\"Back to Home\"}]]}],[]],\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]}],[\"$\",\"footer\",null,{\"className\":\"border-t mt-12\",\"style\":{\"borderColor\":\"var(--bg-border)\",\"backgroundColor\":\"var(--bg-secondary)\"},\"children\":[\"$\",\"div\",null,{\"className\":\"max-w-4xl mx-auto px-6 py-12\",\"children\":[[\"$\",\"div\",null,{\"className\":\"grid grid-cols-1 md:grid-cols-3 gap-8 mb-8\",\"children\":[[\"$\",\"div\",null,{\"children\":[[\"$\",\"h3\",null,{\"className\":\"text-lg font-bold mb-2\",\"style\":{\"color\":\"var(--accent)\"},\"children\":\"BlackCatDesigns\"}],[\"$\",\"p\",null,{\"className\":\"text-sm\",\"style\":{\"color\":\"var(--text-muted)\"},\"children\":\"Cultivating Aesthetic Transformations\"}]]}],[\"$\",\"div\",null,{\"children\":[[\"$\",\"h4\",null,{\"className\":\"text-sm font-semibold mb-4\",\"style\":{\"color\":\"var(--text-secondary)\"},\"children\":\"Navigation\"}],[\"$\",\"ul\",null,{\"className\":\"space-y-2 text-sm\",\"children\":[[\"$\",\"li\",null,{\"children\":[\"$\",\"$L7\",null,{\"href\":\"/\",\"children\":\"Home\"}]}],[\"$\",\"li\",null,{\"children\":[\"$\",\"$L7\",null,{\"href\":\"/projects\",\"children\":\"Projects\"}]}],[\"$\",\"li\",null,{\"children\":[\"$\",\"$L7\",null,{\"href\":\"/blog\",\"children\":\"Blog\"}]}],[\"$\",\"li\",null,{\"children\":[\"$\",\"$L7\",null,{\"href\":\"/about\",\"children\":\"About\"}]}],[\"$\",\"li\",null,{\"children\":[\"$\",\"$L7\",null,{\"href\":\"/contact\",\"children\":\"Contact\"}]}]]}]]}],[\"$\",\"div\",null,{\"children\":[[\"$\",\"h4\",null,{\"className\":\"text-sm font-semibold mb-4\",\"style\":{\"color\":\"var(--text-secondary)\"},\"children\":\"Connect\"}],[\"$\",\"ul\",null,{\"className\":\"space-y-2 text-sm\",\"children\":[[\"$\",\"li\",null,{\"children\":[\"$\",\"$L7\",null,{\"href\":\"https://github.com/theblackcat98\",\"external\":true,\"children\":[\"$\",\"span\",null,{\"className\":\"flex items-center gap-2\",\"children\":[[\"$\",\"svg\",null,{\"ref\":\"$undefined\",\"xmlns\":\"http://www.w3.org/2000/svg\",\"width\":24,\"height\":24,\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":2,\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"className\":\"lucide lucide-github w-4 h-4\",\"aria-hidden\":\"true\",\"children\":[[\"$\",\"path\",\"tonef\",{\"d\":\"M15 22v-4a4.8 4.8 0 0 0-1-3.5c3 0 6-2 6-5.5.08-1.25-.27-2.48-1-3.5.28-1.15.28-2.35 0-3.5 0 0-1 0-3 1.5-2.64-.5-5.36-.5-8 0C6 2 5 2 5 2c-.3 1.15-.3 2.35 0 3.5A5.403 5.403 0 0 0 4 9c0 3.5 3 5.5 6 5.5-.39.49-.68 1.05-.85 1.65-.17.6-.22 1.23-.15 1.85v4\"}],\"$L8\",\"$undefined\"]}],\"GitHub\"]}]}]}],\"$L9\"]}]]}]]}],\"$La\"]}]}]]}]]}]]}],{\"children\":[\"blog\",\"$Lb\",{\"children\":[\"__PAGE__\",\"$Lc\",{},null,false]},null,false]},null,false],\"$Ld\",false]],\"m\":\"$undefined\",\"G\":[\"$e\",[]],\"s\":false,\"S\":true}\n"])</script><script>self.__next_f.push([1,"f:I[1318,[\"619\",\"static/chunks/619-ba102abea3e3d0e4.js\",\"831\",\"static/chunks/app/blog/page-546ed3538b42ce2a.js\"],\"default\"]\n17:I[4431,[],\"ViewportBoundary\"]\n19:I[4431,[],\"MetadataBoundary\"]\n1a:\"$Sreact.suspense\"\n8:[\"$\",\"path\",\"9comsn\",{\"d\":\"M9 18c-4.51 2-5-2-7-2\"}]\n"])</script><script>self.__next_f.push([1,"9:[\"$\",\"li\",null,{\"children\":[\"$\",\"$L7\",null,{\"href\":\"https://instagram.com/theblackcat98\",\"external\":true,\"children\":[\"$\",\"span\",null,{\"className\":\"flex items-center gap-2\",\"children\":[[\"$\",\"svg\",null,{\"ref\":\"$undefined\",\"xmlns\":\"http://www.w3.org/2000/svg\",\"width\":24,\"height\":24,\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":2,\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"className\":\"lucide lucide-instagram w-4 h-4\",\"aria-hidden\":\"true\",\"children\":[[\"$\",\"rect\",\"2e1cvw\",{\"width\":\"20\",\"height\":\"20\",\"x\":\"2\",\"y\":\"2\",\"rx\":\"5\",\"ry\":\"5\"}],[\"$\",\"path\",\"9exkf1\",{\"d\":\"M16 11.37A4 4 0 1 1 12.63 8 4 4 0 0 1 16 11.37z\"}],[\"$\",\"line\",\"r4j83e\",{\"x1\":\"17.5\",\"x2\":\"17.51\",\"y1\":\"6.5\",\"y2\":\"6.5\"}],\"$undefined\"]}],\"Instagram\"]}]}]}]\n"])</script><script>self.__next_f.push([1,"a:[\"$\",\"div\",null,{\"className\":\"border-t pt-6 text-center text-sm\",\"style\":{\"borderColor\":\"var(--bg-border)\",\"color\":\"var(--text-muted)\"},\"children\":[\"$\",\"p\",null,{\"children\":\"Â© 2025 BlackCatDesigns. All rights reserved.\"}]}]\nb:[\"$\",\"$1\",\"c\",{\"children\":[null,[\"$\",\"$L4\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L5\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]]}]\n10:T260d,"])</script><script>self.__next_f.push([1,"\n# Evaluating New LLMs: Why It's Getting Harder and What to Do\n\nIn the fast-paced world of artificial intelligence, new large language models (LLMs) emerge almost weekly, each promising breakthroughs in reasoning, creativity, or efficiency. But how do we reliably assess their true capabilities? This post explores why evaluating these models is becoming increasingly difficult amid rapid advancements, and offers practical strategiesâ€”including custom tests and essential toolsâ€”to navigate the benchmarking landscape. Why does this matter? Without robust evaluation, we risk deploying unreliable AI systems that could falter in real-world applications.\n\n## Why It's Getting Harder\n\nThe explosion of LLM development has outpaced our ability to evaluate them effectively. Traditional benchmarks, once reliable yardsticks, now struggle to keep up with models that evolve at breakneck speed. For instance, as models grow larger and more sophisticated, evaluation frameworks face scalability issues, particularly with behemoths like GPT-4 successors that boast billions of parameters.\u003cgrok-card data-id=\"0dea5c\" data-type=\"citation_card\"\u003e\u003c/grok-card\u003e What happens when a benchmark designed for yesterday's AI meets tomorrow's giant?\n\n### Rapid Releases and Benchmark Saturation\n\nOne core challenge is the sheer velocity of new model releases. In 2025 alone, we've seen dozens of iterations from companies like OpenAI, Anthropic, and xAI, each tweaking architectures or training data. This rapid cycle leads to \"benchmark saturation,\" where models achieve near-perfect scores on established tests like MMLU or Hellaswag, rendering them less discriminative.\u003cgrok-card data-id=\"030c0a\" data-type=\"citation_card\"\u003e\u003c/grok-card\u003e Older benchmarks become outdated quickly, as models overfit to publicly available test sets through contaminationâ€”data leaking into training corpora unintentionally.\u003cgrok-card data-id=\"1f2169\" data-type=\"citation_card\"\u003e\u003c/grok-card\u003e Imagine training for a marathon only to find the course has changed overnight; evaluators must constantly adapt.\n\nMoreover, performance varies wildly across tasks. A model excelling in coding might flop in reasoning or factual accuracy, complicating holistic assessments.\u003cgrok-card data-id=\"eb075d\" data-type=\"citation_card\"\u003e\u003c/grok-card\u003e This task-specific variability demands more nuanced approaches, but with releases accelerating, keeping evaluations current feels like chasing a moving target.\n\n### Biases, Inconsistencies, and Subjectivity\n\nHuman evaluation, long the gold standard, grapples with repeatability and inherent biases.\u003cgrok-card data-id=\"813057\" data-type=\"citation_card\"\u003e\u003c/grok-card\u003e Evaluators might favor LLM-generated text over human-written content, introducing systematic skews.\u003cgrok-card data-id=\"ecee09\" data-type=\"citation_card\"\u003e\u003c/grok-card\u003e LLMs themselves, when used as judges, exhibit inconsistenciesâ€”producing different scores for identical inputs across runs.\u003cgrok-card data-id=\"98cffb\" data-type=\"citation_card\"\u003e\u003c/grok-card\u003e Why trust an AI evaluator that's as fickle as the models it assesses?\n\nSubjectivity compounds this: Metrics like \"helpfulness\" or \"creativity\" lack objective anchors, leading to debates over what constitutes success.\u003cgrok-card data-id=\"623c71\" data-type=\"citation_card\"\u003e\u003c/grok-card\u003e In high-stakes domains like medicine or law, where precision is paramount, these flaws could have real consequences.\u003cgrok-card data-id=\"81d373\" data-type=\"citation_card\"\u003e\u003c/grok-card\u003e Non-determinism in generative AI adds another layer, as outputs vary even with fixed prompts.\u003cgrok-card data-id=\"f42768\" data-type=\"citation_card\"\u003e\u003c/grok-card\u003e These issues highlight a broader crisis: Our tools for measurement aren't evolving as fast as the tech they measure.\n\n### Exploitation and Reliability Gaps\n\nRecent research uncovers vulnerabilities, such as LLMs failing on novel tasks or being tricked into harmful outputs by adversaries.\u003cgrok-card data-id=\"705039\" data-type=\"citation_card\"\u003e\u003c/grok-card\u003e Fairness and bias remain persistent headaches, with models perpetuating societal inequities unless rigorously tested.\u003cgrok-card data-id=\"574e99\" data-type=\"citation_card\"\u003e\u003c/grok-card\u003e As multimodal capabilities growâ€”handling text, images, and moreâ€”evaluation must expand beyond words, yet many benchmarks lag in this integration.\n\n## Strategies for Benchmarking: Custom Tests\n\nTo counter these hurdles, shift from off-the-shelf benchmarks to tailored evaluations. Custom tests allow you to probe specific use cases, ensuring relevance to your needs. But how do you build them without reinventing the wheel?\n\n### Designing Effective Custom Evaluations\n\nStart with a clear framework: Define your objectives, such as assessing reasoning in domain-specific scenarios.\u003cgrok-card data-id=\"f9c5a7\" data-type=\"citation_card\"\u003e\u003c/grok-card\u003e Create datasets that mimic real-world inputs, avoiding contamination by sourcing fresh data. For example, craft prompts testing edge cases like ambiguous queries or adversarial attacks.\n\nLeverage LLMs themselves for evaluationâ€”use one model to score another's outputs against golden responses for nuanced feedback.\u003cgrok-card data-id=\"bfb59a\" data-type=\"citation_card\"\u003e\u003c/grok-card\u003e This \"LLM-as-judge\" approach scales better than human review, though mitigate biases by averaging multiple runs. Incorporate metrics like BLEU for similarity or custom rubrics for qualitative traits.\n\n### Examples and Best Practices\n\nConsider building internal benchmarks for your application, like a set of 100+ queries tailored to customer service or code generation.\u003cgrok-card data-id=\"550efe\" data-type=\"citation_card\"\u003e\u003c/grok-card\u003e Test for consistency by running evaluations multiple times and analyzing variance. Tools like DeepEval can help enforce JSON-structured outputs for easy parsing.\u003cgrok-card data-id=\"7119c0\" data-type=\"citation_card\"\u003e\u003c/grok-card\u003e\n\nPro tip: Combine offline (pre-deployment) and online (user feedback) testing for comprehensive insights.\u003cgrok-card data-id=\"263c45\" data-type=\"citation_card\"\u003e\u003c/grok-card\u003e What if your custom test reveals a model's weakness in long-context reasoning? Iterate by fine-tuning or selecting alternatives.\n\n## Tools for Evaluation\n\nA robust toolkit is essential for efficient benchmarking. Here's a curated selection of 2025's top options, each addressing different facets of LLM assessment.\n\n### Standardized Benchmarks and Platforms\n\nEvidently AI offers over 30 benchmarks, from MMLU for knowledge to Chatbot Arena for conversational prowess, with easy integration links.\u003cgrok-card data-id=\"9076f6\" data-type=\"citation_card\"\u003e\u003c/grok-card\u003e LiveBench stands out for its contamination-resistant design, generating fresh questions monthly to keep tests dynamic.\u003cgrok-card data-id=\"b9bf19\" data-type=\"citation_card\"\u003e\u003c/grok-card\u003e\n\nFor agentic behaviors, AgentBench evaluates LLMs in interactive environments, simulating real tasks like planning or tool use.\u003cgrok-card data-id=\"1819bd\" data-type=\"citation_card\"\u003e\u003c/grok-card\u003e Deepchecks provides a user-friendly interface for comprehensive checks, ideal for teams building custom workflows.\u003cgrok-card data-id=\"bbac7d\" data-type=\"citation_card\"\u003e\u003c/grok-card\u003e\n\n### Specialized and Scalable Tools\n\nNVIDIA's GenAI-Perf focuses on inference benchmarking, measuring speed and efficiency for deployment scenarios.\u003cgrok-card data-id=\"fb5905\" data-type=\"citation_card\"\u003e\u003c/grok-card\u003e Confident AI delivers open-source implementations for bird's-eye evaluations, including metrics and datasets.\u003cgrok-card data-id=\"44c318\" data-type=\"citation_card\"\u003e\u003c/grok-card\u003e For materials science or niche domains, MatTools offers standardized frameworks to adapt benchmarks.\u003cgrok-card data-id=\"40c56c\" data-type=\"citation_card\"\u003e\u003c/grok-card\u003e\n\nPatronus AI emphasizes systematic testing with strategies for reliability.\u003cgrok-card data-id=\"38ac7d\" data-type=\"citation_card\"\u003e\u003c/grok-card\u003e These tools collectively enable scalable, automated evalsâ€”crucial as models balloon in size.\n\n## Future Challenges\n\nLooking ahead, AI evaluation will grapple with even thornier issues. As models achieve superhuman feats, benchmarks must evolve to prevent overfitting and capture true generalization.\u003cgrok-card data-id=\"ddf37f\" data-type=\"citation_card\"\u003e\u003c/grok-card\u003e Ethical considerations, like ensuring fairness in multimodal systems, will demand new protocols.\u003cgrok-card data-id=\"df44f8\" data-type=\"citation_card\"\u003e\u003c/grok-card\u003e\n\nAutomated tools promise relief, but governance remains keyâ€”robust evals are hard to implement without standardized policies.\u003cgrok-card data-id=\"96524f\" data-type=\"citation_card\"\u003e\u003c/grok-card\u003e In agentic AI, where models act autonomously, evaluation shifts to real-time monitoring for misuse or hallucinations.\u003cgrok-card data-id=\"7b1e98\" data-type=\"citation_card\"\u003e\u003c/grok-card\u003e What safeguards will we need as AI integrates deeper into workplaces and societies?\n\nEmerging trends include sovereign AI for data privacy and physical embodiments, each introducing unique assessment hurdles.\u003cgrok-card data-id=\"a0dfbd\" data-type=\"citation_card\"\u003e\u003c/grok-card\u003e Scalability with trillion-parameter models will test computational limits, pushing for efficient, distributed eval systems.\n\n## Conclusion\n\nEvaluating new LLMs is tougher than ever due to rapid advancements, biases, and outdated tools, but strategies like custom tests and platforms such as LiveBench or Deepchecks offer a path forward. By designing tailored benchmarks and leveraging automated evaluators, we can better discern model strengths and weaknesses. As AI evolves, staying curious about these challenges ensures we build trustworthy systems. What innovative eval method will you try next? Embrace these approaches to keep pace with the AI revolution.\n\n*(Word count: 1,152)*\n"])</script><script>self.__next_f.push([1,"11:T15c8,"])</script><script>self.__next_f.push([1,"\n# Getting Started with Local LLMs: 2025 Beginnerâ€™s Guide\n\nRunning large language models locally has never been more accessible. Whether youâ€™re experimenting, building private apps, or just curious, you can now get state-of-the-art performance without sending your data to the cloud.\n\nThis guide cuts through the noise and gives you exactly what you need to get started in 2025 â€“ with clear recommendations, hardware reality checks, and practical commands.\n\n## âš¡ TL;DR â€“ The Fast Path\n\n**Easiest start** â†’ **Ollama**  \n**Maximum efficiency \u0026 control** â†’ **llama.cpp**  \n**High-throughput serving** â†’ **vLLM** or **Hugging Face TGI**  \n**Single-GPU API** â†’ **TabbyAPI**\n\n**Best starter models (2025):**\n- Qwen3-4B â†’ tiny but surprisingly capable\n- Qwen3-14B â†’ excellent reasoning\n- gpt-oss (MoE) â†’ efficiency king for long contexts\n\n**Hardware cheat sheet (quantized):**\n- 8â€“12 GB VRAM â†’ 4Bâ€“8B models\n- 16â€“24 GB VRAM â†’ 14Bâ€“30B models\n- 40+ GB VRAM â†’ 70B+ models\n\nGot **20 GB VRAM + 32 GB RAM**? Youâ€™re in the sweet spot for 14B at 32k context or 4B at 128k.\n\n## ðŸ§µ 3-Step Quick Start (Takes \u003c10 Minutes)\n\n```bash\n# 1. Install Ollama (macOS, Windows, Linux)\n# Visit https://ollama.com and download\n\n# 2. Pull and run a great starter model\nollama pull qwen3:4b\nollama run qwen3:4b\n\n# 3. Want longer context? (if the model supports YaRN/RoPE scaling)\nollama run qwen3:4b --num_ctx 32768\n```\n\nThatâ€™s it. Youâ€™re now running a local LLM.\n\n## ðŸ–¥ Choose Your Inference Engine\n\n| Tool              | Best For                          | Difficulty | Notes                                      |\n|-------------------|-----------------------------------|------------|--------------------------------------------|\n| **Ollama**        | Beginners, quick chat, prototyping| â˜…â˜†â˜†â˜†â˜†     | Simple CLI + API, works with OpenWebUI     |\n| **llama.cpp**     | Max speed \u0026 control, edge devices | â˜…â˜…â˜†â˜†â˜†     | Extremely efficient, huge community        |\n| **vLLM**          | High-throughput GPU serving       | â˜…â˜…â˜…â˜†â˜†     | PagedAttention = more tokens/sec           |\n| **Hugging Face TGI** | Production-grade API servers    | â˜…â˜…â˜…â˜†â˜†     | OpenAI-compatible, great multi-GPU         |\n| **TabbyAPI**      | Lightweight single-GPU API        | â˜…â˜…â˜†â˜†â˜†     | Fast setup, works great with OpenWebUI     |\n| **TensorRT-LLM**  | Peak NVIDIA performance           | â˜…â˜…â˜…â˜…â˜†     | Complex but fastest on RTX 40/H100         |\n\nStart with **Ollama**. Graduate to **llama.cpp** or **vLLM** when you outgrow it.\n\n## ðŸ–¼ Recommended Frontends (Optional but Nice)\n\n- **OpenWebUI** â€“ Beautiful browser interface (works with Ollama, TabbyAPI, vLLM)\n- **LM Studio** â€“ Excellent model manager + local OpenAI-compatible server\n- **Jan** â€“ Clean, cross-platform, open-source\n\n## âš™ï¸ Hardware Reality Check (2025)\n\n| Resource     | Minimum          | Recommended         | Notes                                      |\n|--------------|------------------|---------------------|--------------------------------------------|\n| GPU          | RTX 3060 12 GB   | RTX 4090 / A6000+   | NVIDIA dominates local inference           |\n| VRAM         | 8 GB             | 24 GB+              | The #1 bottleneck                          |\n| System RAM   | 16 GB            | 32â€“64 GB            | Needed for KV cache spillover              |\n| Storage      | 50 GB free       | NVMe SSD            | Quantized models: 2â€“50 GB each             |\n\n**Pro tip**: Mixture-of-Experts (MoE) models like Mixtral 8x7B activate only 7B parameters per token, gpt-oss activates ~1.7B â†’ they punch way above their weight on hybrid CPU+GPU setups.\n\n## ðŸ“– Quick Vocabulary (Youâ€™ll Hear These Terms)\n\n- **GGUF** â€“ The go-to format for quantized models (used by Ollama \u0026 llama.cpp)\n- **Quantization** â€“ Compressing model weights (Q4_K_M = great balance)\n- **Context** â€“ How much text the model can â€œseeâ€ at once\n- **KV Cache** â€“ Memory that grows with context length (VRAM eater)\n- **YaRN / RoPE Scaling** â€“ Tricks to extend context beyond original training\n- **MoE** â€“ Only a fraction of the model runs per token â†’ efficient\n- **PagedAttention** â€“ vLLMâ€™s secret sauce for high throughput\n\n## ðŸ“ Context vs VRAM Cheat Sheet (Q4_K_M Quantized)\n\n| Model              | 32k Context | 64k Context | 128k Context | Notes                              |\n|--------------------|-------------|-------------|--------------|------------------------------------|\n| Qwen3-4B           | 5â€“6 GB      | 10â€“12 GB    | 20â€“24 GB     | Perfect for modest GPUs            |\n| Qwen3-14B          | 16â€“20 GB    | 32â€“38 GB    | Not advised  | Sweet spot at 32k                  |\n| gpt-oss (MoE) | 10â€“12 GB    | 20â€“24 GB    | 40â€“48 GB     | Best efficiency for long contexts  |\n\n## ðŸ”§ Practical Tips for Your Rig (20 GB VRAM + 32 GB RAM Example)\n\n- Run **Qwen3-14B** comfortably at 32k context\n- Use **Qwen3-4B** when you need 64kâ€“128k\n- Pick **gpt-oss** for the best long-context efficiency\n- Default to **Q4_K_M** quantization â€“ best quality/size tradeoff\n- Most backends support OpenAI-compatible APIs â†’ swap tools by changing a URL\n\n## âœ… Your Next Steps\n\n1. Install **Ollama** (or your chosen engine)\n2. Try **qwen3:4b** or **qwen3:14b**\n3. Experiment with `--num_ctx` for longer context\n4. Add **OpenWebUI** or **LM Studio** for a nicer experience\n\nLocal LLMs are evolving fast â€“ new models, better quantization, and longer contexts drop almost monthly. Bookmark this guide and check back.\n\n"])</script><script>self.__next_f.push([1,"12:T1fe2,"])</script><script>self.__next_f.push([1,"\n# The Evolution of System Prompts for Deep Research Agents\n\nSystem promptsâ€”those foundational instructions that guide AI behaviorâ€”have come a long way since the dawn of generative models. In 2025, they're no longer mere directives but intricate scaffolds enabling deep research agents to autonomously explore, synthesize, and verify knowledge. What started as basic commands in GPT-1 has evolved into dynamic, tool-integrated chains that power tools like OpenWebUI. Why does this matter? As AI agents tackle complex queries, well-crafted prompts determine whether outputs are insightful or illusory. This post unpacks the journey, key innovations, persistent hurdles, and ways to experiment forward.\n\n## From Zero-Shot Whispers to Chained Reasoning: A Historical Arc\n\n### The Dawn of Prompting in Early GPTs (2018â€“2021)\nOpenAI's GPT-1 in 2018 introduced the transformer decoder for text generation, but prompts were rudimentary: simple continuations like \"Complete this sentence.\" GPT-2 (2019) added scale, handling zero-shot tasksâ€”predicting outputs without examplesâ€”but outputs often wandered into incoherence. By GPT-3 (2020), few-shot prompting emerged: embedding examples in prompts to generalize tasks like translation or summarization. These were static, one-off instructions, limited by the model's inability to \"think\" step-by-step. Early users hacked creativity with tricks like role-playing (\"You are a helpful assistant\"), but hallucinationsâ€”fabricated factsâ€”plagued results. What if prompts could guide reasoning, not just recall?\n\n### The Instruct Era and RLHF Refinement (2022â€“2024)\nChatGPT's launch in late 2022, powered by GPT-3.5 with reinforcement learning from human feedback (RLHF), marked a pivot. System prompts now enforced alignment: \"Respond concisely and truthfully.\" This reduced chaos, but complex tasks still faltered. Chain-of-thought (CoT) prompting in 2023â€”appending \"Think step by step\"â€”boosted arithmetic and logic by 20â€“50% on benchmarks. GPT-4 (2023) integrated multimodal inputs, with prompts specifying formats like JSON for structured outputs. Yet, as agents like Auto-GPT (2023) emerged, prompts needed recursion: self-generating sub-instructions for multi-step workflows. The era's lesson? Prompts must mimic human cognition to scale beyond chit-chat.\n\n### 2025: Agents Awaken with Structured Chains\nBy mid-2025, GPT-5's release fused reasoning models (e.g., o3) with routers that auto-select fast or deep modes based on prompt complexity. Prompts now orchestrate agentic flows: decomposing queries into subtasks, invoking tools, and iterating outputs. In OpenWebUI, a open-source interface for local LLMs, prompts drive \"Deep Research\" functionsâ€”autonomous agents that plan queries, fetch via APIs, and synthesize cited reports. Unlike static RAG (retrieval-augmented generation), these chains enable long-horizon planning: parallel searches, memory pruning, and self-verification. The result? Agents that don't just answerâ€”they investigate.\n\n## Core Building Blocks: Role, Tools, and Multi-Turn Flows\n\n### Role-Playing: Assigning Agency\nEffective prompts begin with persona: \"You are an elite research analyst with deep domain knowledge in science and finance.\" This anchors behavior, reducing drift. In 2025 agents, roles extend to multi-agent systems: one for query decomposition, another for synthesis. Why? It mirrors human teams, distributing cognitive load.\n\n### Tool-Calling Syntax: From Text to Action\nModern prompts embed XML-like syntax for tools: `\u003ctool\u003eweb_search(query=\"AI ethics 2025\")\u003c/tool\u003e`. OpenWebUI's functions parse these for DuckDuckGo integration or code execution. GPT-5's router enhances this, dynamically chaining tools based on context. Prompts specify outputs: \"Return JSON with {sources: [], summary: ''}.\"\n\n### Multi-Turn Flows: Chaining for Depth\nPrompt chaining breaks tasks into pipelines: output of one feeds the next. Example in OpenWebUI for \"Use web search then summarize\":\n\n1. **Step 1 Prompt**: \"Decompose query '{user_query}' into 3 sub-queries. Output: JSON array.\"\n2. **Step 2 (Parallel)**: For each sub-query, \"Search web: {sub_query}. Extract top 3 facts with URLs.\"\n3. **Step 3**: \"Synthesize facts into a 200-word summary. Cite sources inline.\"\n\nThis yields verifiable reports, as in GPT Researcher's STORM multi-agent setup. What happens if a chain loops? It risks inefficiencyâ€”hence, prompts cap iterations: \"Max 5 turns or conclude.\"\n\n#### Pro Tip: Embed Error Handling\nAdd: \"If data is insufficient, flag and suggest refinements.\" This builds resilience.\n\n## Taming the Beast: Hallucination Mitigation Challenges\n\nEven advanced chains falter. Hallucinationsâ€”confident fabricationsâ€”affect 20â€“50% of outputs in knowledge tasks. In 2025, causes include training incentives rewarding fluency over truth, plus long-context dilution.\n\nMitigations via prompts:\n- **Grounding**: \"Base responses only on provided sources. If uncertain, say 'Insufficient data'.\"\n- **Self-Check**: CoT with verification: \"After drafting, cross-reference facts against sources.\"\n- **Structured Outputs**: Enforce tables for claims: \"| Claim | Source | Confidence |\".\n\n| Technique | Example Prompt Snippet | Impact on Hallucinations |\n|-----------|-------------------------|--------------------------|\n| **Chain-of-Verification** | \"Generate claim â†’ Retrieve evidence â†’ Revise if mismatch.\" | Reduces by 30% in RAG setups |\n| **Abstention Allowance** | \"If \u003c70% confident, abstain and explain.\" | Cuts overconfidence by 40% |\n| **Few-Shot Grounding** | Include verified examples: \"Query: X â†’ Facts: Y (cite Z).\" | Boosts factual recall 25% |\n\nYet challenges persist: Multilingual biases amplify in global agents, and compute costs soar for iterative checks. Why does this endure? LLMs optimize for coherence, not veracityâ€”prompts alone can't fully rewrite incentives.\n\n## Community Wisdom: Best Practices from GitHub Repos\n\nOpen-source thrives on shared prompts. Repos like dair-ai/Prompt-Engineering-Guide offer notebooks for CoT and RAG tuning. dontriskit/awesome-ai-system-prompts curates agentic examples, emphasizing domain rules: \"For research: Prioritize peer-reviewed sources; format as Markdown with citations.\"\n\nKey practices:\n- **Modularity**: Use templates with variables: \"Research {topic} using {tool}.\"\n- **Iteration**: Version prompts via diffs, testing on benchmarks.\n- **Safety**: Embed ethics: \"Avoid bias; flag uncertainties.\"\n\nFrom x1xhlol/system-prompts-and-models-of-ai-tools, Claude Code's prompt stresses \"Research-first: Verify before acting.\" Communities like Reddit's r/OpenWebUI share Deep Research tweaks, blending prompts with functions for verifiable outputs.\n\n## Dynamic Horizons: Experiments with Variables\n\nTo future-proof, infuse variability. In OpenWebUI, custom variables turn prompts into templates: \"{num_queries:3} sub-searches on {topic}, temperature {temp:0.7}.\" LangChain's expression language enables runtime injection: Pull schemas dynamically for graph RAG.\n\n**Experiment Ideas**:\n1. **A/B Testing**: Chain with/without variables; measure hallucination via self-scores.\n2. **Adaptive Temperature**: \"If {complexity:high}, set temp=0.2 for precision.\"\n3. **Few-Shot Retrieval**: Dynamically fetch examples: \"Retrieve 2 similar queries from DB.\"\n\nTry in OpenWebUI: Load a Deep Research model, vary {max_iterations:2â€“5}, and log synthesis quality. What emerges? Prompts that evolve with data, not just users.\n\n## Final Thoughts: Prompts as the Soul of Agency\nFrom GPT-1's raw predictions to 2025's autonomous researchers, system prompts have scripted AI's ascentâ€”chaining thought, tools, and verification into something profoundly capable. Yet, as agents like those in OpenWebUI probe deeper, the real evolution lies in our stewardship: crafting prompts that prioritize truth over fluency. We've mitigated hallucinations, but can we instill curiosity that questions its own chains? Experiment boldlyâ€”your next variable might unlock the uncharted. What's one prompt tweak you'll test today?\n\n\u003e *Inspired by the open-source ethos: Share your chains on GitHub, and let's build verifiable futures together.*\n"])</script><script>self.__next_f.push([1,"13:T760,"])</script><script>self.__next_f.push([1,"\n# Essential Design Principles\n\nGood design is invisible. When done right, users don't notice the thoughtful decisions behind itâ€”they just enjoy the experience. Let's explore the key principles that make design work.\n\n## 1. Simplicity\n\nThe best designs are often the simplest ones. Remove unnecessary elements and focus on what matters.\n\n\u003e \"Simplicity is the ultimate sophistication\" - Leonardo da Vinci\n\nWhen you strip away the unnecessary, you're left with the essential. This principle applies to:\n\n- **Visual hierarchy** - Guide the user's attention\n- **Navigation** - Make it obvious how to move through your design\n- **Content** - Use clear, concise language\n\n## 2. Consistency\n\nUsers learn from patterns. When design elements behave consistently, users feel confident using your product.\n\nConsistency includes:\n\n- Visual consistency (colors, typography, spacing)\n- Behavioral consistency (interactions work the same way)\n- Conceptual consistency (ideas and patterns are unified)\n\n## 3. Feedback \u0026 Visibility\n\nUsers need to understand the result of their actions. Every interaction should provide feedback.\n\nExamples of good feedback:\n\n1. Visual responses (button highlights, loading states)\n2. Error messages that help, not confuse\n3. Progress indicators for long operations\n4. Confirmation messages for critical actions\n\n## 4. Accessibility\n\nDesign for everyone. This means considering:\n\n- Color contrast for readability\n- Keyboard navigation support\n- Alt text for images\n- Clear focus indicators\n- Semantic HTML structure\n\n## 5. White Space\n\nWhite space (or negative space) is not wasted space. It helps:\n\n- Reduce cognitive load\n- Create visual separation\n- Improve readability\n- Draw attention to key elements\n\n## Conclusion\n\nThese principles form the foundation of great design. Apply them thoughtfully to create experiences that are beautiful, functional, and delightful.\n"])</script><script>self.__next_f.push([1,"14:T78d,"])</script><script>self.__next_f.push([1,"\n# Markdown Cheat Sheet\n\nThanks for visiting [The Markdown Guide](https://www.markdownguide.org)!\n\nThis Markdown cheat sheet provides a quick overview of all the Markdown syntax elements. It can't cover every edge case, so if you need more information about any of these elements, refer to the reference guides for [basic syntax](https://www.markdownguide.org/basic-syntax/) and [extended syntax](https://www.markdownguide.org/extended-syntax/).\n\n## Basic Syntax\n\nThese are the elements outlined in John Gruber's original design document. All Markdown applications support these elements.\n\n### Headings\n\n# H1\n## H2\n### H3\n\n### Bold\n\n**bold text**\n\n### Italic\n\n*italicized text*\n\n### Blockquote\n\n\u003e blockquote\n\n### Ordered List\n\n1. First item\n2. Second item\n3. Third item\n\n### Unordered List\n\n- First item\n- Second item\n- Third item\n\n### Code\n\n`code`\n\n### Horizontal Rule\n\n---\n\n### Link\n\n[Markdown Guide](https://www.markdownguide.org)\n\n### Image\n\n![alt text](https://www.markdownguide.org/assets/images/tux.png)\n\n## Extended Syntax\n\nThese elements extend the basic syntax by adding additional features. Not all Markdown applications support these elements.\n\n### Table\n\n| Syntax | Description |\n| ----------- | ----------- |\n| Header | Title |\n| Paragraph | Text |\n\n### Fenced Code Block\n\n```json\n{\n  \"firstName\": \"John\",\n  \"lastName\": \"Smith\",\n  \"age\": 25\n}\n```\n\n```md\n# test\n\n## h2\n```\n\n### Strikethrough\n\n~~The world is flat.~~\n\n### Task List\n\n- [x] Write the press release\n- [ ] Update the website\n- [ ] Contact the media\n\n### Highlight\n\nI need to highlight these ==very important words==.\n\n### Subscript\n\nH~2~O\n\n### Superscript\n\nX^2^\n\n### Highlight\n\nI need to highlight these ==very important words==.\n\n### Emoji\n\nThat is so funny! :joy:\n\nCheck out these emojis: :rocket: :star: :heart: :thumbsup: :fire: :tada:\n\n### Water Formula\n\nThe chemical formula for water is H~2~O\n\n### Math Expression\n\nEinstein's famous equation: E=MC^2^\n"])</script><script>self.__next_f.push([1,"c:[\"$\",\"$1\",\"c\",{\"children\":[[\"$\",\"div\",null,{\"className\":\"space-y-8\",\"children\":[[\"$\",\"div\",null,{\"className\":\"flex items-start justify-between gap-4\",\"children\":[[\"$\",\"div\",null,{\"children\":[[\"$\",\"h1\",null,{\"className\":\"text-4xl font-bold mb-2\",\"style\":{\"color\":\"var(--text-primary)\"},\"children\":\"Blog\"}],[\"$\",\"p\",null,{\"style\":{\"color\":\"var(--text-secondary)\"},\"children\":\"Thoughts on web development, technology, and more.\"}]]}],[\"$\",\"$Lf\",null,{\"posts\":[{\"slug\":\"benchmarks-and-llms\",\"content\":\"$10\",\"title\":\"Evaluating New LLMs: Why It's Getting Harder and What to Do\",\"date\":\"2025-11-28\",\"description\":\"Explanatory strategies for benchmarking amid rapid AI releases. Covering custom tests, tools, and future challenges.\",\"author\":\"theblackcat\",\"tags\":[\"AI Evaluation\",\"LLMs\",\"Benchmarking\",\"Tools\",\"Future Challenges\"],\"published\":true,\"readingTime\":6,\"coverImage\":\"\"},{\"slug\":\"llm-starter-guide\",\"content\":\"$11\",\"title\":\"Getting Started with Local LLMs: 2025 Beginnerâ€™s Guide\",\"date\":\"2025-11-28\",\"description\":\"A clear, no-nonsense guide to running powerful large language models on your own hardware in 2025 â€“ perfect for beginners and power users alike.\",\"author\":\"theblackcat\",\"tags\":[\"local-llm\",\"ai\",\"ollama\",\"llama-cpp\",\"self-hosted\",\"2025\"],\"published\":true,\"readingTime\":4,\"coverImage\":\"\"},{\"slug\":\"system-prompts-of-the-past\",\"content\":\"$12\",\"title\":\"The Evolution of System Prompts for Deep Research Agents\",\"date\":\"2025-11-28\",\"description\":\"From simple instructions in early GPTs to sophisticated chain-of-thought structures in 2025 tools like OpenWebUI, this post traces how prompts have transformed AI research capabilities. Explore historical shifts, key techniques, challenges, and forward-looking experiments.\",\"author\":\"theblackcat\",\"tags\":[\"AI prompts\",\"prompt engineering\",\"deep research agents\",\"LLM evolution\",\"OpenWebUI\",\"hallucination mitigation\"],\"published\":true,\"readingTime\":6,\"coverImage\":\"\"},{\"slug\":\"welcome\",\"content\":\"\\n# Welcome to My Blog!\\n\\nThis is your first blog post. It's written in Markdown and will be automatically rendered into a beautiful HTML page.\\n\\n## What You Can Do\\n\\n- Write blog posts in simple Markdown format\\n- Add frontmatter metadata (title, date, tags, etc.)\\n- Automatically generate a blog listing page\\n- Create individual post pages with styling\\n\\n## Getting Started\\n\\nTo add more blog posts:\\n\\n1. Create a new `.md` file in the `public/posts/` directory\\n2. Add frontmatter at the top with metadata\\n3. Write your content in Markdown\\n4. The post will automatically appear on your blog!\\n\\n## Markdown Support\\n\\nYou can use all standard Markdown features:\\n\\n- **Bold text**\\n- *Italic text*\\n- [Links](https://example.com)\\n- ==Highlighting==\\n- ~~Strikethrough~~ \\n- Code blocks with syntax highlighting\\n\\n```javascript\\nfunction hello() {\\n  console.log(\\\"Hello, World!\\\");\\n}\\n```\\n\\nLists are supported too:\\n\\n1. First item\\n2. Second item\\n3. Third item\\n\\nFeel free to customize this post or delete it and create your own!\\n\",\"title\":\"Welcome to My Blog\",\"date\":\"2025-11-28\",\"description\":\"An introduction to my personal blog and portfolio\",\"author\":\"You\",\"tags\":[\"welcome\",\"first-post\"],\"published\":true,\"readingTime\":1,\"coverImage\":\"\"},{\"slug\":\"design-principles\",\"content\":\"$13\",\"title\":\"Essential Design Principles\",\"date\":\"2025-11-27\",\"description\":\"Explore the fundamental principles that guide beautiful and functional design\",\"author\":\"You\",\"tags\":[\"design\",\"ui-ux\"],\"published\":true,\"readingTime\":2,\"coverImage\":\"\"},{\"slug\":\"markdown-cheatsheet\",\"content\":\"$14\",\"title\":\"Markdown Cheat Sheet\",\"date\":\"2025-11-26\",\"description\":\"A cheat sheet to show all Markdown styles and features\",\"author\":\"You\",\"tags\":[\"writing\",\"development\",\"markdown\"],\"published\":true,\"readingTime\":2,\"coverImage\":\"\"}]}]]}],\"$L15\"]}],null,\"$L16\"]}]\n"])</script><script>self.__next_f.push([1,"d:[\"$\",\"$1\",\"h\",{\"children\":[null,[[\"$\",\"$L17\",null,{\"children\":\"$L18\"}],null],[\"$\",\"$L19\",null,{\"children\":[\"$\",\"div\",null,{\"hidden\":true,\"children\":[\"$\",\"$1a\",null,{\"fallback\":null,\"children\":\"$L1b\"}]}]}]]}]\n"])</script><script>self.__next_f.push([1,"1c:I[9467,[\"619\",\"static/chunks/619-ba102abea3e3d0e4.js\",\"831\",\"static/chunks/app/blog/page-546ed3538b42ce2a.js\"],\"default\"]\n1d:I[4431,[],\"OutletBoundary\"]\n1f:I[5278,[],\"AsyncMetadataOutlet\"]\n15:[\"$\",\"$L1c\",null,{\"posts\":\"$c:props:children:0:props:children:0:props:children:1:props:posts\",\"allCategories\":[\"2025\",\"AI Evaluation\",\"AI prompts\",\"Benchmarking\",\"Future Challenges\",\"LLM evolution\",\"LLMs\",\"OpenWebUI\",\"Tools\",\"ai\",\"deep research agents\",\"design\",\"development\",\"first-post\",\"hallucination mitigation\",\"llama-cpp\",\"local-llm\",\"markdown\",\"ollama\",\"prompt engineering\",\"self-hosted\",\"ui-ux\",\"welcome\",\"writing\"]}]\n16:[\"$\",\"$L1d\",null,{\"children\":[\"$L1e\",[\"$\",\"$L1f\",null,{\"promise\":\"$@20\"}]]}]\n"])</script><script>self.__next_f.push([1,"18:[[\"$\",\"meta\",\"0\",{\"charSet\":\"utf-8\"}],[\"$\",\"meta\",\"1\",{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1\"}]]\n"])</script><script>self.__next_f.push([1,"1e:null\n"])</script><script>self.__next_f.push([1,"20:{\"metadata\":[[\"$\",\"title\",\"0\",{\"children\":\"Portfolio \u0026 Blog\"}],[\"$\",\"meta\",\"1\",{\"name\":\"description\",\"content\":\"Personal portfolio and blog featuring my work and thoughts\"}]],\"error\":null,\"digest\":\"$undefined\"}\n1b:\"$20:metadata\"\n"])</script></body></html>